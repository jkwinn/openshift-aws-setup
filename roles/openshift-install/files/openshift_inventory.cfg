# Create an OSEv3 group that contains the masters and nodes groups
[OSEv3:children]
masters
nodes
{% if install_gluster %}
glusterfs
{% endif %}

# Set variables common for all OSEv3 hosts
[OSEv3:vars]

# SSH user, this user should allow ssh based auth without requiring a password
ansible_ssh_user=ec2-user

# If ansible_ssh_user is not root, ansible_become must be set to true
ansible_become=true

# Set cloud provider to AWS
# Note experiencing issues with this on first install, as workaround
# install it without the cloud provider and then ssh to bastion, uncomment
# in openshift_inventory.cfg and re-run installation from bastion directly
openshift_cloudprovider_kind=aws
openshift_clusterid={{namespace}}
openshift_cloudprovider_aws_access_key={{ lookup('env','AWS_ACCESS_KEY_ID') }}
openshift_cloudprovider_aws_secret_key={{ lookup('env','AWS_SECRET_ACCESS_KEY') }}
openshift_storageclass_parameters={'type': 'gp2', 'encrypted': 'false', 'zone': '{{availability_zone}}'}

deployment_type={{deployment_type}}

# We need a wildcard DNS setup for our public access to services
openshift_master_default_subdomain={{public_subdomain_prefix}}.{{public_dns_zone}}

{% if change_default_web_port %}
# Some corporate networks do not allow 8443, so we should provide the option to change
openshift_master_console_port={{openshift_master_console_port}}
{% endif %}

{% if change_default_api_port %}
# Changing the default API port
openshift_master_api_port={{openshift_master_api_port}}
{% endif %}

# Comment the following to enable htpasswd authentication; defaults to DenyAllPasswordIdentityProvider
openshift_master_identity_providers=[{'name': 'htpasswd_auth', 'login': 'true', 'challenge': 'true', 'kind': 'HTPasswdPasswordIdentityProvider', 'filename': '{{ htpasswd_path }}'}]

{% if install_metrics %}
# See: https://docs.openshift.com/enterprise/latest/install_config/cluster_metrics.html
openshift_metrics_install_metrics=true
openshift_metrics_storage_kind=dynamic
{% endif %}

{% if install_logging %}
# See: https://docs.openshift.com/enterprise/latest/install_config/aggregate_logging.html
openshift_logging_install_logging=true
openshift_logging_storage_kind=dynamic
{% endif %}

{% if install_prometheus %}
openshift_hosted_prometheus_deploy=true
openshift_prometheus_storage_type=pvc
openshift_prometheus_alertmanager_storage_type=pvc
openshift_prometheus_alertbuffer_storage_type=pvc

# Bug in 3.7 https://bugzilla.redhat.com/show_bug.cgi?id=1522977 if you enabled the below
# openshift_prometheus_node_selector={"region":"infra"}
{% endif %}

{% if master_ssl_key_file is defined and master_ssl_key_file is defined %}
openshift_master_named_certificates=[{"certfile":"/home/{{amazon_user}}/certs/{{public_dns_zone}}/{{ master_ssl_cert_file | basename }}","keyfile":"/home/{{amazon_user}}/certs/{{public_dns_zone}}/{{master_ssl_key_file | basename }}"}]
openshift_master_overwrite_named_certificates=true
{% endif %}

# Do not run apps on master
{% if install_node_selector %}
osm_default_node_selector="region=primary"
{% endif %}

{% if disable_service_catalog %}
openshift_enable_service_catalog=false
{% endif %}

#disable checks
openshift_disable_check=docker_storage,docker_storage_driver,memory_availability,package_version

# Create the masters host group. 
[masters]
{{master_private_dns_name}} openshift_public_hostname={{public_dns_zone}}

# host group for etcd
[etcd]
{{master_private_dns_name}}

# host group for nodes, includes region info
[nodes]
{{master_private_dns_name}} openshift_node_labels="{'region': 'infra', 'zone': 'default'}" openshift_schedulable=true
{% for node in nodes_ip %}
{% if node.gluster %}
{{node.private_dns_name}}
{% else %}
{{node.private_dns_name}} openshift_node_labels="{'region': 'primary', 'zone': '{{ 'west' if loop.index is divisibleby 2 else 'east'}}'}"
{% endif %}
{% endfor %}

{% if install_gluster %}
[glusterfs]
{% for node in nodes_ip %}
{% if node.gluster %}
{{node.private_dns_name}} glusterfs_devices="[ '/dev/xvdc' ]"
{% endif %}
{% endfor %}
{% endif %}
